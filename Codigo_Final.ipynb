{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-08-01T00:54:28.212291Z","iopub.status.busy":"2023-08-01T00:54:28.211853Z","iopub.status.idle":"2023-08-01T00:54:43.164083Z","shell.execute_reply":"2023-08-01T00:54:43.162889Z","shell.execute_reply.started":"2023-08-01T00:54:28.212239Z"},"trusted":true},"outputs":[],"source":["!pip install -q transformers\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-05T02:16:41.407083Z","iopub.status.busy":"2023-08-05T02:16:41.406669Z","iopub.status.idle":"2023-08-05T02:16:56.907194Z","shell.execute_reply":"2023-08-05T02:16:56.906170Z","shell.execute_reply.started":"2023-08-05T02:16:41.407050Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from tqdm.auto import tqdm\n","import tensorflow as tf\n","from transformers import BertTokenizer\n","from nltk.corpus import stopwords\n","from contextlib import redirect_stdout\n","import keras\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import make_classification\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","from transformers import TFBertModel"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-05T02:17:10.505378Z","iopub.status.busy":"2023-08-05T02:17:10.504008Z","iopub.status.idle":"2023-08-05T02:17:10.809699Z","shell.execute_reply":"2023-08-05T02:17:10.808648Z","shell.execute_reply.started":"2023-08-05T02:17:10.505327Z"},"trusted":true},"outputs":[],"source":["train = pd.read_csv(\"train_data.csv\")\n","test = pd.read_csv(\"test_data.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-05T02:17:10.811691Z","iopub.status.busy":"2023-08-05T02:17:10.811375Z","iopub.status.idle":"2023-08-05T02:17:10.900697Z","shell.execute_reply":"2023-08-05T02:17:10.899702Z","shell.execute_reply.started":"2023-08-05T02:17:10.811665Z"},"trusted":true},"outputs":[],"source":["train.loc[train['labels'] == 'ANALYSIS', 'labels'] = 0\n","train.loc[train['labels'] == 'FAC', 'labels'] = 1\n","train.loc[train['labels'] == 'PREAMBLE', 'labels'] = 2\n","train.loc[train['labels'] == 'PRE_RELIED', 'labels'] = 3\n","train.loc[train['labels'] == 'NONE', 'labels'] = 4\n","train.loc[train['labels'] == 'ARG_PETITIONER', 'labels'] = 5\n","train.loc[train['labels'] == 'RPC', 'labels'] = 6\n","train.loc[train['labels'] == 'RLC', 'labels'] = 7\n","train.loc[train['labels'] == 'ARG_RESPONDENT', 'labels'] = 8\n","train.loc[train['labels'] == 'RATIO', 'labels'] = 9\n","train.loc[train['labels'] == 'STA', 'labels'] = 10\n","train.loc[train['labels'] == 'ISSUE', 'labels'] = 11\n","train.loc[train['labels'] == 'PRE_NOT_RELIED', 'labels'] = 12"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-05T02:17:11.041054Z","iopub.status.busy":"2023-08-05T02:17:11.039731Z","iopub.status.idle":"2023-08-05T02:17:11.061297Z","shell.execute_reply":"2023-08-05T02:17:11.060250Z","shell.execute_reply.started":"2023-08-05T02:17:11.041010Z"},"trusted":true},"outputs":[],"source":["test.loc[test['labels'] == 'ANALYSIS', 'labels'] = 0\n","test.loc[test['labels'] == 'FAC', 'labels'] = 1\n","test.loc[test['labels'] == 'PREAMBLE', 'labels'] = 2\n","test.loc[test['labels'] == 'PRE_RELIED', 'labels'] = 3\n","test.loc[test['labels'] == 'NONE', 'labels'] = 4\n","test.loc[test['labels'] == 'ARG_PETITIONER', 'labels'] = 5\n","test.loc[test['labels'] == 'RPC', 'labels'] = 6\n","test.loc[test['labels'] == 'RLC', 'labels'] = 7\n","test.loc[test['labels'] == 'ARG_RESPONDENT', 'labels'] = 8\n","test.loc[test['labels'] == 'RATIO', 'labels'] = 9\n","test.loc[test['labels'] == 'STA', 'labels'] = 10\n","test.loc[test['labels'] == 'ISSUE', 'labels'] = 11\n","test.loc[test['labels'] == 'PRE_NOT_RELIED', 'labels'] = 12"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-05T02:17:13.411744Z","iopub.status.busy":"2023-08-05T02:17:13.411167Z","iopub.status.idle":"2023-08-05T02:17:15.230754Z","shell.execute_reply":"2023-08-05T02:17:15.229546Z","shell.execute_reply.started":"2023-08-05T02:17:13.411701Z"},"trusted":true},"outputs":[],"source":["stop = stopwords.words('english')\n","train['text_without_stopwords'] = train['text'].str.lower().apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-05T02:17:29.780175Z","iopub.status.busy":"2023-08-05T02:17:29.779693Z","iopub.status.idle":"2023-08-05T02:17:30.260868Z","shell.execute_reply":"2023-08-05T02:17:30.259615Z","shell.execute_reply.started":"2023-08-05T02:17:29.780140Z"},"trusted":true},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-05T02:17:30.263293Z","iopub.status.busy":"2023-08-05T02:17:30.262860Z","iopub.status.idle":"2023-08-05T02:17:38.795210Z","shell.execute_reply":"2023-08-05T02:17:38.793971Z","shell.execute_reply.started":"2023-08-05T02:17:30.263261Z"},"trusted":true},"outputs":[],"source":["model = TFBertModel.from_pretrained('bert-base-cased') # bert base model with pretrained weights"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-05T02:17:38.797937Z","iopub.status.busy":"2023-08-05T02:17:38.797514Z","iopub.status.idle":"2023-08-05T02:17:38.807735Z","shell.execute_reply":"2023-08-05T02:17:38.806247Z","shell.execute_reply.started":"2023-08-05T02:17:38.797899Z"},"trusted":true},"outputs":[],"source":["token = tokenizer.encode_plus(\n","    train['text_without_stopwords'].iloc[0], \n","    max_length=512, \n","    truncation=True,\n","    padding='max_length', \n","    add_special_tokens=True,\n","    return_tensors='tf'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-05T02:17:38.810091Z","iopub.status.busy":"2023-08-05T02:17:38.809662Z","iopub.status.idle":"2023-08-05T02:17:38.820511Z","shell.execute_reply":"2023-08-05T02:17:38.819523Z","shell.execute_reply.started":"2023-08-05T02:17:38.810053Z"},"trusted":true},"outputs":[],"source":["X_input_ids = np.zeros((len(train), 512))\n","X_attn_masks = np.zeros((len(train), 512))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-05T02:17:38.825533Z","iopub.status.busy":"2023-08-05T02:17:38.825139Z","iopub.status.idle":"2023-08-05T02:17:38.836450Z","shell.execute_reply":"2023-08-05T02:17:38.835242Z","shell.execute_reply.started":"2023-08-05T02:17:38.825502Z"},"trusted":true},"outputs":[],"source":["def generate_training_data(df, ids, masks, tokenizer):\n","    for i, text in tqdm(enumerate(df['text_without_stopwords'])):\n","        tokenized_text = tokenizer.encode_plus(\n","            text,\n","            max_length=512, \n","            truncation=True, \n","            padding='max_length', \n","            add_special_tokens=True,\n","            return_tensors='tf'\n","        )\n","        ids[i, :] = tokenized_text.input_ids\n","        masks[i, :] = tokenized_text.attention_mask\n","    return ids, masks\n","\n","def prepare_data(input_text, tokenizer):\n","    token = tokenizer.encode_plus(\n","        input_text,\n","        max_length=512, \n","        truncation=True, \n","        padding='max_length', \n","        add_special_tokens=True,\n","        return_tensors='tf'\n","    )\n","    return {\n","        'input_ids': tf.cast(token.input_ids, tf.float64),\n","        'attention_mask': tf.cast(token.attention_mask, tf.float64)\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-05T02:17:38.839667Z","iopub.status.busy":"2023-08-05T02:17:38.838989Z","iopub.status.idle":"2023-08-05T02:18:09.966899Z","shell.execute_reply":"2023-08-05T02:18:09.965581Z","shell.execute_reply.started":"2023-08-05T02:17:38.839635Z"},"trusted":true},"outputs":[],"source":["X_input_ids, X_attn_masks = generate_training_data(train, X_input_ids, X_attn_masks, tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-05T02:18:09.969121Z","iopub.status.busy":"2023-08-05T02:18:09.968599Z","iopub.status.idle":"2023-08-05T02:18:09.978489Z","shell.execute_reply":"2023-08-05T02:18:09.977428Z","shell.execute_reply.started":"2023-08-05T02:18:09.969079Z"},"trusted":true},"outputs":[],"source":["labels = np.zeros((len(train), 13))\n","labels.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-05T02:18:09.980294Z","iopub.status.busy":"2023-08-05T02:18:09.979918Z","iopub.status.idle":"2023-08-05T02:18:11.443492Z","shell.execute_reply":"2023-08-05T02:18:11.442106Z","shell.execute_reply.started":"2023-08-05T02:18:09.980265Z"},"trusted":true},"outputs":[],"source":["labels[np.arange(len(train)), train['labels'].values.tolist()] = 1 # one-hot encoded target tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-05T02:18:11.445324Z","iopub.status.busy":"2023-08-05T02:18:11.444952Z","iopub.status.idle":"2023-08-05T02:18:11.674029Z","shell.execute_reply":"2023-08-05T02:18:11.672659Z","shell.execute_reply.started":"2023-08-05T02:18:11.445293Z"},"trusted":true},"outputs":[],"source":["np.unique(labels, axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-05T02:18:11.675842Z","iopub.status.busy":"2023-08-05T02:18:11.675428Z","iopub.status.idle":"2023-08-05T02:18:11.818518Z","shell.execute_reply":"2023-08-05T02:18:11.817508Z","shell.execute_reply.started":"2023-08-05T02:18:11.675812Z"},"trusted":true},"outputs":[],"source":["dataset = tf.data.Dataset.from_tensor_slices((X_input_ids, X_attn_masks, labels))\n","dataset.take(0) # one sample data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-05T02:18:11.823437Z","iopub.status.busy":"2023-08-05T02:18:11.822512Z","iopub.status.idle":"2023-08-05T02:18:11.829037Z","shell.execute_reply":"2023-08-05T02:18:11.828055Z","shell.execute_reply.started":"2023-08-05T02:18:11.823396Z"},"trusted":true},"outputs":[],"source":["def SentimentDatasetMapFunction(input_ids, attn_masks, labels):\n","    return {\n","        'input_ids': input_ids,\n","        'attention_mask': attn_masks\n","    }, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-05T02:18:11.830821Z","iopub.status.busy":"2023-08-05T02:18:11.830515Z","iopub.status.idle":"2023-08-05T02:18:11.907219Z","shell.execute_reply":"2023-08-05T02:18:11.905993Z","shell.execute_reply.started":"2023-08-05T02:18:11.830798Z"},"trusted":true},"outputs":[],"source":["dataset = dataset.map(SentimentDatasetMapFunction) # converting to required format for tensorflow dataset "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-05T02:18:11.909041Z","iopub.status.busy":"2023-08-05T02:18:11.908688Z","iopub.status.idle":"2023-08-05T02:18:11.924773Z","shell.execute_reply":"2023-08-05T02:18:11.923544Z","shell.execute_reply.started":"2023-08-05T02:18:11.909012Z"},"trusted":true},"outputs":[],"source":["dataset = dataset.shuffle(10000).batch(16, drop_remainder=True) # batch size, drop any left out tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-05T02:18:11.926572Z","iopub.status.busy":"2023-08-05T02:18:11.926159Z","iopub.status.idle":"2023-08-05T02:18:11.932625Z","shell.execute_reply":"2023-08-05T02:18:11.931242Z","shell.execute_reply.started":"2023-08-05T02:18:11.926539Z"},"trusted":true},"outputs":[],"source":["p = 1\n","train_size = int((len(train)//16)*p) # for each 16 batch of data we will have len(df)//16 samples, take 80% of that for train."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-05T02:18:11.935649Z","iopub.status.busy":"2023-08-05T02:18:11.935207Z","iopub.status.idle":"2023-08-05T02:18:11.950932Z","shell.execute_reply":"2023-08-05T02:18:11.949473Z","shell.execute_reply.started":"2023-08-05T02:18:11.935610Z"},"trusted":true},"outputs":[],"source":["train_dataset = dataset.take(train_size)\n","val_dataset = dataset.skip(train_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-05T02:30:40.737219Z","iopub.status.busy":"2023-08-05T02:30:40.736727Z","iopub.status.idle":"2023-08-05T02:30:40.743403Z","shell.execute_reply":"2023-08-05T02:30:40.741959Z","shell.execute_reply.started":"2023-08-05T02:30:40.737167Z"},"trusted":true},"outputs":[],"source":["params = [{'dense': 32, 'learning_rate': 1e-5*16}, {'dense': 64, 'learning_rate': 1e-5*8}, {'dense': 128, 'learning_rate': 1e-5*4},{'dense': 256, 'learning_rate': 1e-5*2}, {'dense': 512, 'learning_rate': 1e-5}, {'dense': 1024, 'learning_rate': 1e-5/2}]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-05T02:31:01.527479Z","iopub.status.busy":"2023-08-05T02:31:01.527044Z","iopub.status.idle":"2023-08-05T02:32:11.691965Z","shell.execute_reply":"2023-08-05T02:32:11.690272Z","shell.execute_reply.started":"2023-08-05T02:31:01.527448Z"},"trusted":true},"outputs":[],"source":["for param in params:\n","    print('Inicio do processo com o modelo de ' + str(param['dense']) + ' camadas')\n","    \n","    # defining 2 input dense for input_ids and attn_masks\n","    input_ids = tf.keras.Input(shape=(512,), name='input_ids', dtype='int32')\n","    attn_masks = tf.keras.Input(shape=(512,), name='attention_mask', dtype='int32')\n","\n","    bert_embds = model.bert(input_ids, attention_mask=attn_masks)[1]\n","    intermediate_layer = tf.keras.layers.Dense(param['dense'], activation='relu', name='intermediate_layer')(bert_embds)\n","    intermediate_layer2 = tf.keras.layers.Dense(param['dense']*2, activation='relu', name='intermediate_layer2')(intermediate_layer)\n","    intermediate_layer3 = tf.keras.layers.Dense(param['dense'], activation='relu', name='intermediate_layer3')(intermediate_layer2)\n","    output_layer = tf.keras.layers.Dense(13, activation='softmax', name='output_layer')(intermediate_layer3)\n","\n","    rr_model = tf.keras.Model(inputs=[input_ids, attn_masks], outputs=output_layer)\n","    rr_model.summary()\n","    \n","    with open('/kaggle/working/' + str(param['dense']) + '_modelsummary.csv', 'w') as f:\n","        with redirect_stdout(f):\n","            rr_model.summary()\n","            \n","    print('Summary exportado')\n","    \n","    optim = tf.keras.optimizers.legacy.Adam(learning_rate=param['learning_rate'], decay=1e-6)\n","    loss_func = tf.keras.losses.CategoricalCrossentropy()\n","    acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n","    \n","    rr_model.compile(optimizer=optim, loss=loss_func, metrics=[acc])\n","    \n","    print('Treinamento iniciado')\n","    hist = rr_model.fit(\n","    train_dataset,\n","    validation_data=val_dataset,\n","    epochs=5\n","    )\n","    \n","    rr_model.save(str(param['dense']) + '_rr_classification_model.h5')\n","    print('Modelo com ' + str(param['dense']) + ' camadas exportado')\n","    \n","    output = []\n","    \n","    for i in test[\"text\"]:\n","        input = prepare_data(i, tokenizer)\n","        predict = rr_model(input)\n","        output.append(np.argmax(predict).tolist())\n","    print('Teste do modelo de ' + str(param['dense']) + ' camadas finalizado')\n","    \n","    df_out = pd.DataFrame(output, columns = [\"labels\"])\n","    df_out_id = pd.DataFrame(test[\"id\"], columns = [\"id\"])\n","    df_out_id[\"labels\"] = df_out[\"labels\"]\n","    \n","    \n","    df_out_id.to_csv(str(param['dense']) + '_predict.csv', index=False)\n","    print('Saida do modelo de ' + str(param['dense']) + ' camadas exportada')\n","    \n","    y_true = test[\"labels\"].tolist()\n","    y_pred = df_out_id['labels'].tolist()\n","    cm = confusion_matrix(y_true, y_pred)\n","\n","    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['ANALYSIS', 'FAC', 'PREAMBLE', 'PRE_RELIED', 'NONE', 'ARG_PETITIONER', \n","                                                  'RPC', 'RLC', 'ARG_RESPONDENT', 'RATIO', 'STA', 'ISSUE', 'PRE_NOT_RELIED'])\n","\n","    disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')\n","    plt.savefig(str(param['dense']) + '_cm.png', bbox_inches='tight')\n","    print('Matriz de confusao do modelo de ' + str(param['dense']) + ' camadas exportada')\n","    \n","    metrics = classification_report(y_true, y_pred)\n","    with open(str(param['dense']) + '_metrics.csv', 'w') as out:\n","        out.write(metrics)\n","        \n","    print('Metrics do modelo de ' + str(param['dense']) + ' camadas exportada')\n","    print('Processo do modelo de ' + str(param['dense']) + ' camadas finalizado')\n","    "]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
